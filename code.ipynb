{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hatespeech' 'normal' 'offensive']\n",
      "['non-toxic' 'toxic']\n"
     ]
    }
   ],
   "source": [
    "encoder_classes = np.load('HateXplain/Data/classes.npy', allow_pickle=True)\n",
    "encoder_two_classes = np.load('HateXplain/Data/classes_two.npy', allow_pickle=True)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = encoder_classes\n",
    "\n",
    "encoder_two = LabelEncoder()\n",
    "encoder_two.classes_ = encoder_two_classes\n",
    "\n",
    "print(encoder.classes_)\n",
    "print(encoder_two.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HateXplain/Data/dataset.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "with open('HateXplain/Data/post_id_divisions.json', 'r') as f1:\n",
    "    splitter = json.load(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "train\n",
      "val\n",
      "1924\n",
      "15383\n",
      "1922\n"
     ]
    }
   ],
   "source": [
    "for i in splitter.keys():\n",
    "    print(i)\n",
    "    \n",
    "print(len(splitter['test']))\n",
    "print(len(splitter['train']))\n",
    "print(len(splitter['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for j in data.keys():\n",
    "#    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_id : Unique id for each post\n",
    "\n",
    "ðŸ”¹annotators : The list of annotations from each annotator\n",
    "\n",
    "ðŸ”¹annotators[label] : The label assigned by the annotator to this post. Possible values: [Hatespeech, Offensive, Normal]\n",
    "\n",
    "ðŸ”¹annotators[annotator_id] : The unique Id assigned to each annotator\n",
    "\n",
    "ðŸ”¹annotators[target] : A list of target community present in the post\n",
    "\n",
    "ðŸ”¹rationales : A list of rationales selected by annotators. Each rationales represents a list with values 0 or 1. A value of 1 means that the token is part of the rationale selected by the annotator. To get the particular token, we can use the same index position in \"post_tokens\"\n",
    "\n",
    "ðŸ”¹post_tokens : The list of tokens representing the post which was annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Post ID       Label                     Target  \\\n",
      "0                 23107796_gab  hatespeech               Hindu, Islam   \n",
      "1                  9995600_gab   offensive  Minority, Refugee, Indian   \n",
      "2                  9995600_gab   offensive                     Indian   \n",
      "3  1227920812235051008_twitter   offensive                      Other   \n",
      "4  1204931715778543624_twitter   offensive                      Hindu   \n",
      "\n",
      "                               Hate Text  \\\n",
      "0            [raped neo nazi would rape]   \n",
      "1                        [paki migrants]   \n",
      "2                                 [paki]   \n",
      "3  [chutiya retards stophindiimposition]   \n",
      "4                          [hate hindus]   \n",
      "\n",
      "                                       Complete Text  \n",
      "0  u really think i would not have been raped by ...  \n",
      "1  the uk has threatened to return radioactive wa...  \n",
      "2  the uk has threatened to return radioactive wa...  \n",
      "3  if english is not imposition then hindi is als...  \n",
      "4  no liberal congratulated hindu refugees post c...  \n"
     ]
    }
   ],
   "source": [
    "post_ids = []\n",
    "labels = []\n",
    "targets = []\n",
    "part_of_sentence = []\n",
    "full_texts = []\n",
    "\n",
    "\n",
    "def get_part_of_sentence(rationales, post_tokens):\n",
    "    #print(rationales)\n",
    "    #print(post_tokens)\n",
    "    parts = []\n",
    "    for r in rationales:\n",
    "        part = [post_tokens[k] for k, val in enumerate(r) if val == 1]\n",
    "        #print(part)\n",
    "        parts.append(' '.join(part))\n",
    "    return parts\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for post_id in splitter[split]:\n",
    "        if post_id in data:\n",
    "            post_data = data[post_id]\n",
    "            full_text = ' '.join(post_data['post_tokens']) #Taking full text\n",
    "            #print(full_text)\n",
    "            #print(len(post_data['annotators']))\n",
    "            for i, annotator in enumerate(post_data['annotators']):\n",
    "                #print(annotator)\n",
    "\n",
    "                #print(targets)\n",
    "                #print(len(post_data['rationales']))\n",
    "                #print(len(post_data['annotators']))\n",
    "                \n",
    "                if i+1 <len(post_data['rationales']):\n",
    "                    part_of_sentence.append(get_part_of_sentence([post_data['rationales'][i]], post_data['post_tokens']))\n",
    "                    post_ids.append(post_id)\n",
    "                    labels.append(annotator['label'])\n",
    "                    targets.append(', '.join(annotator['target']))\n",
    "                    full_texts.append(full_text)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Post ID': post_ids,\n",
    "    'Label': labels,\n",
    "    'Target': targets,\n",
    "    'Hate Text': part_of_sentence,\n",
    "    'Complete Text': full_texts\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Target</th>\n",
       "      <th>Hate Text</th>\n",
       "      <th>Complete Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23107796_gab</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Hindu, Islam</td>\n",
       "      <td>[raped neo nazi would rape]</td>\n",
       "      <td>u really think i would not have been raped by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Minority, Refugee, Indian</td>\n",
       "      <td>[paki migrants]</td>\n",
       "      <td>the uk has threatened to return radioactive wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Indian</td>\n",
       "      <td>[paki]</td>\n",
       "      <td>the uk has threatened to return radioactive wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1227920812235051008_twitter</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Other</td>\n",
       "      <td>[chutiya retards stophindiimposition]</td>\n",
       "      <td>if english is not imposition then hindi is als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1204931715778543624_twitter</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Hindu</td>\n",
       "      <td>[hate hindus]</td>\n",
       "      <td>no liberal congratulated hindu refugees post c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15800</th>\n",
       "      <td>1231804803614830592_twitter</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Other</td>\n",
       "      <td>[retarded]</td>\n",
       "      <td>4 chan is retarded and so are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15801</th>\n",
       "      <td>26732378_gab</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>[kike]</td>\n",
       "      <td>plenty of e celebs have covered israid sending...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15802</th>\n",
       "      <td>26732378_gab</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>[kike]</td>\n",
       "      <td>plenty of e celebs have covered israid sending...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15803</th>\n",
       "      <td>14030104_gab</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>[kikey]</td>\n",
       "      <td>yeah i got to about just over &lt;number&gt; followe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15804</th>\n",
       "      <td>14030104_gab</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>[shoahed kikey]</td>\n",
       "      <td>yeah i got to about just over &lt;number&gt; followe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15805 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Post ID       Label                     Target  \\\n",
       "0                     23107796_gab  hatespeech               Hindu, Islam   \n",
       "1                      9995600_gab   offensive  Minority, Refugee, Indian   \n",
       "2                      9995600_gab   offensive                     Indian   \n",
       "3      1227920812235051008_twitter   offensive                      Other   \n",
       "4      1204931715778543624_twitter   offensive                      Hindu   \n",
       "...                            ...         ...                        ...   \n",
       "15800  1231804803614830592_twitter   offensive                      Other   \n",
       "15801                 26732378_gab  hatespeech                     Jewish   \n",
       "15802                 26732378_gab  hatespeech                     Jewish   \n",
       "15803                 14030104_gab  hatespeech                     Jewish   \n",
       "15804                 14030104_gab   offensive                     Jewish   \n",
       "\n",
       "                                   Hate Text  \\\n",
       "0                [raped neo nazi would rape]   \n",
       "1                            [paki migrants]   \n",
       "2                                     [paki]   \n",
       "3      [chutiya retards stophindiimposition]   \n",
       "4                              [hate hindus]   \n",
       "...                                      ...   \n",
       "15800                             [retarded]   \n",
       "15801                                 [kike]   \n",
       "15802                                 [kike]   \n",
       "15803                                [kikey]   \n",
       "15804                        [shoahed kikey]   \n",
       "\n",
       "                                           Complete Text  \n",
       "0      u really think i would not have been raped by ...  \n",
       "1      the uk has threatened to return radioactive wa...  \n",
       "2      the uk has threatened to return radioactive wa...  \n",
       "3      if english is not imposition then hindi is als...  \n",
       "4      no liberal congratulated hindu refugees post c...  \n",
       "...                                                  ...  \n",
       "15800                  4 chan is retarded and so are you  \n",
       "15801  plenty of e celebs have covered israid sending...  \n",
       "15802  plenty of e celebs have covered israid sending...  \n",
       "15803  yeah i got to about just over <number> followe...  \n",
       "15804  yeah i got to about just over <number> followe...  \n",
       "\n",
       "[15805 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
